import os
import fitz  # PyMuPDF
import pandas as pd

# Function to extract product statuses
def extract_product_status(doc):
    status = {"Products": "No", "ECH": "No", "ADC": "No"}  # Default states
    for page in doc:
        # Extract text instances to find checkboxes' positions
        text_instances = page.search_for("Products") + page.search_for("ECH") + page.search_for("ADC")
        # Extract annotations (widgets) which are usually form fields
        for annot in page.annots():
            if annot.type[0] == 18:  # Widget type for form fields in PDF
                # Check positions to determine if this annot is near a product name
                annot_rect = annot.rect
                for inst in text_instances:
                    if annot_rect.intersects(inst):
                        # If near, determine if it is checked
                        if annot.field_value == "Yes":  # Assuming 'Yes' represents a checked state
                            product_name = page.get_text("text", clip=inst).strip()
                            status[product_name] = "Yes"
    return status

# List all PDF files in the current directory
pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]
data = []

# Read eECH PDF and extract the required information
for file_name in pdf_files:
    with fitz.open(file_name) as doc:
        products_status = extract_product_status(doc)
        parts = file_name.replace('.pdf', '').split('---')
        if len(parts) >= 4:
            document_date = parts[2]
            customer_name = parts[3].replace('-', ' ')
            tax_id = parts[4]
            data.append({
                "Document Date": document_date,
                "Customer Name": customer_name,
                "Tax ID": tax_id,
                "SSA Product": products_status["Products"],
                "ECH": products_status["ECH"],
                "ADC": products_status["ADC"]
            })

# Convert to DataFrame
df = pd.DataFrame(data)
print(df)


----

import os
import pandas as pd
from PyPDF2 import PdfReader

# Function to extract text from a PDF file
def extract_pdf_text(pdf_file):
    reader = PdfReader(pdf_file)
    text = ""
    for page in reader.pages:
        text += page.extract_text()
    return text

# Function to extract tabular data from the extracted text
def extract_tabular_data(text):
    lines = text.split('\n')
    table_data = []
    # Look for table start, assuming fixed format with known headers
    for i, line in enumerate(lines):
        if "Tax ID" in line and "Legal/Primary Name" in line:
            table_start = i + 1
            break
    else:
        table_start = len(lines)
    
    # Extract data from table rows
    for line in lines[table_start:]:
        if line.strip() == "" or "Page" in line:  # End of table
            break
        parts = line.split()
        tax_id = parts[0]
        legal_name = " ".join(parts[1:-2])
        tms = parts[-2]
        bsa_kyc = parts[-1]
        table_data.append({'Tax ID': tax_id, 'Legal/Primary Name': legal_name, 'TMS': tms, 'BSA KYC': bsa_kyc})
    return table_data

# Function to check for product implementation
def parse_product_implementation(text):
    bsa_product = "No"
    ach = "No"
    rdc = "No"
    print("Extracted Text:\n", text)  # Debugging output
    lines = text.splitlines()
    for line in lines:
        if "Products" in line:
            if "" in line or "✔" in line:
                bsa_product = "Yes"
        if "ACH" in line:
            if "" in line or "✔" in line:
                ach = "Yes"
        if "RDC" in line:
            if "" in line or "✔" in line:
                rdc = "Yes"
    return bsa_product, ach, rdc

# Prepare a list to hold all extracted data
data = []

# List all PDF files in the current directory
pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]

# Loop through each PDF file and extract the information
for file_name in pdf_files:
    parts = file_name.replace('.pdf', '').split('---')
    if len(parts) >= 4:
        document_date = parts[2]
        customer_name = parts[3].replace('-', ' ')
        tax_id = parts[4]
        
        # Extract text from the PDF
        text = extract_pdf_text(file_name)
        
        # Parse product implementation and table data
        bsa_product, ach, rdc = parse_product_implementation(text)
        table_data = extract_tabular_data(text)
        
        # Append extracted data including tabular data
        data.append({
            "Document Date": document_date,
            "Customer Name": customer_name,
            "Tax ID": tax_id,
            "BSA Product": bsa_product,
            "ACH": ach,
            "RDC": rdc,
            "Additional Info": table_data  # Append the table data as part of the entry
        })

# Convert the list to a DataFrame
df = pd.DataFrame(data)

# Display the DataFrame
print(df)

# newer version
import re
import os
import pandas as pd
from PyPDF2 import PdfReader

# Function to extract text from a PDF file
def extract_pdf_text(pdf_file):
    reader = PdfReader(pdf_file)
    text = ""
    for page in reader.pages:
        text += page.extract_text()
    return text

# Function to extract tabular data from the extracted text
def extract_tabular_data(text):
    lines = text.split('\n')
    table_data = []
    regex = r"(\d{2}-\d+)\s+([\w\s]+?)\s+(Yes|No)\s+(.*)"
    start_extracting = False
    for line in lines:
        if "Tax ID Legal/Primary Name TMS BSA KYC" in line:
            start_extracting = True
            continue
        if start_extracting:
            if line.strip() == "" or "Page" in line:
                break
            match = re.match(regex, line.strip())
            if match:
                tax_id, legal_name, tms, bsa_kyc = match.groups()
                table_data.append({
                    'Tax ID Entity': tax_id,
                    'Legal Name': legal_name,
                    'TMS': tms,
                    'BSA KYC': bsa_kyc
                })
    return table_data

# List all PDF files in the current directory
pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]

data = []
# Loop through each PDF file and extract the information
for file_name in pdf_files:
    parts = file_name.replace('.pdf', '').split('---')
    if len(parts) >= 4:
        document_date = parts[2]
        customer_name = parts[3].replace('-', ' ')
        tax_id = parts[4]

        # Extract text from the PDF
        text = extract_pdf_text(file_name)

        # Parse the product implementation details (placeholder logic here)
        bsa_product, ach, rdc = "No", "No", "No"  # This needs your actual logic for setting these values based on the text.

        # Extract tabular data
        table_data = extract_tabular_data(text)

        # Combine data from table rows with other extracted details
        for row in table_data:
            data.append({
                "Document Date": document_date,
                "Customer Name": customer_name,
                "Tax ID": tax_id,
                "BSA Product": bsa_product,
                "ACH": ach,
                "RDC": rdc,
                **row
            })

# Create a DataFrame
df = pd.DataFrame(data)

# Print or display the DataFrame
print(df)


-- get all tabular data
import pdfplumber
import pandas as pd
import os

# Define a function to extract text from PDF
def extract_pdf_text(pdf_file):
    with pdfplumber.open(pdf_file) as pdf:
        text = ""
        for page in pdf.pages:
            text += page.extract_text()
        return text

# Function to parse the tabular data from the extracted text
def parse_tabular_data(text):
    lines = text.split('\n')
    data = []
    start = False
    for line in lines:
        if "Tax ID Legal/Primary Name TMS BSA KYC" in line:
            start = True
            continue
        if start and line.strip() == "":
            break
        if start:
            parts = line.split()
            if len(parts) >= 6:
                tax_id = parts[0]
                name = " ".join(parts[1:-2])
                tms = parts[-2]
                bsa_kyc = parts[-1]
                data.append({
                    "Tax ID_new": tax_id,
                    "Legal/Primary Name": name,
                    "TMS": tms,
                    "BSA KYC": bsa_kyc
                })
    return data

# Path to the directory containing PDF files
pdf_directory = "path_to_your_pdf_directory"  # Update with actual path

# Initialize an empty DataFrame to store all results
master_df = pd.DataFrame()

# Loop through each PDF file in the directory
for filename in os.listdir(pdf_directory):
    if filename.endswith('.pdf'):
        pdf_path = os.path.join(pdf_directory, filename)
        
        # Extract text from the PDF file
        pdf_text = extract_pdf_text(pdf_path)
        
        # Parse the extracted text to get data
        new_data = parse_tabular_data(pdf_text)
        
        # Convert the list of dictionaries to a DataFrame
        new_df = pd.DataFrame(new_data)
        
        # Add a static 'Customer Name', 'Document Date', and other known fields
        new_df['Customer Name'] = "Example Company LLC"  # Update as necessary
        new_df['Document Date'] = "6/1/2021"  # Update as necessary
        new_df['BSA Product'] = "Yes"
        new_df['ACH'] = "No"
        new_df['RDC'] = "Yes"

        # Append the new data to the master DataFrame
        master_df = pd.concat([master_df, new_df], ignore_index=True)

# Display the final DataFrame
print(master_df.head())

# Optionally, save the DataFrame to a CSV file
master_df.to_csv("final_output.csv", index=False)

#################Updated#################
import pdfplumber
import pandas as pd
import os

def extract_pdf_text(pdf_file):
    with pdfplumber.open(pdf_file) as pdf:
        text = ""
        for page in pdf.pages:
            text += page.extract_text()
        return text

def parse_tabular_data(text):
    lines = text.split('\n')
    data = []
    start = False
    for line in lines:
        if "Tax ID Legal/Primary Name TMS BSA KYC" in line:
            start = True
            continue
        if start and line.strip() == "":
            break
        if start:
            parts = line.split()
            if len(parts) >= 6:
                tax_id = parts[0]
                name = " ".join(parts[1:-2])
                tms = parts[-2]
                bsa_kyc = parts[-1]
                data.append({
                    "Tax ID_new": tax_id,
                    "Legal/Primary Name": name,
                    "TMS": tms,
                    "BSA KYC": bsa_kyc
                })
    return data

def extract_dynamic_details(filename, text):
    # Extract Customer Name, Document Date from filename if pattern is known
    # Example filename: "Example_Company_LLC-20210601-details.pdf"
    parts = filename.split('-')
    customer_name = parts[0].replace('_', ' ')
    document_date = parts[1][:4] + '-' + parts[1][4:6] + '-' + parts[1][6:]
    
    # Extract BSA Product, ACH, RDC by analyzing the text (set default values or complex logic)
    bsa_product = "Yes" if "BSA Product: Yes" in text else "No"
    ach = "Yes" if "ACH Service: Enabled" in text else "No"
    rdc = "Yes" if "RDC Service: Active" in text else "No"
    
    return customer_name, document_date, bsa_product, ach, rdc

pdf_directory = "path_to_your_pdf_directory"
master_df = pd.DataFrame()

for filename in os.listdir(pdf_directory):
    if filename.endswith('.pdf'):
        pdf_path = os.path.join(pdf_directory, filename)
        pdf_text = extract_pdf_text(pdf_path)
        new_data = parse_tabular_data(pdf_text)
        new_df = pd.DataFrame(new_data)
        
        # Dynamically extract other details from the filename or text
        customer_name, document_date, bsa_product, ach, rdc = extract_dynamic_details(filename, pdf_text)
        new_df['Customer Name'] = customer_name
        new_df['Document Date'] = document_date
        new_df['BSA Product'] = bsa_product
        new_df['ACH'] = ach
        new_df['RDC'] = rdc
        
        master_df = pd.concat([master_df, new_df], ignore_index=True)

print(master_df.head())
master_df.to_csv("final_output.csv", index=False)

##################try################
import pdfplumber
import pandas as pd
import os

def extract_pdf_text(pdf_file):
    with pdfplumber.open(pdf_file) as pdf:
        text = ""
        for page in pdf.pages:
            text += page.extract_text()
        return text

def parse_tabular_data(text):
    lines = text.split('\n')
    data = []
    start = False
    for line in lines:
        if "Tax ID Legal/Primary Name TMS BSA KYC" in line:
            start = True
            continue
        if start and line.strip() == "":
            break
        if start:
            parts = line.split()
            if len(parts) >= 6:
                tax_id = parts[0]
                name = " ".join(parts[1:-2])
                tms = parts[-2]
                bsa_kyc = parts[-1]
                data.append({
                    "Tax ID_new": tax_id,
                    "Legal/Primary Name": name,
                    "TMS": tms,
                    "BSA KYC": bsa_kyc
                })
    return data

def extract_dynamic_details(filename, text):
    parts = filename.split('-')
    customer_name = parts[0].replace('_', ' ')
    document_date = parts[1][:4] + '-' + parts[1][4:6] + '-' + parts[1][6:]
    
    bsa_product = "Yes" if "BSA Product: Yes" in text else "No"
    ach = "Yes" if "ACH Service: Enabled" in text else "No"
    rdc = "Yes" if "RDC Service: Active" in text else "No"
    
    return customer_name, document_date, bsa_product, ach, rdc

# List all PDF files in the current directory
pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]

master_df = pd.DataFrame()

for filename in pdf_files:
    pdf_path = os.path.join('.', filename)
    pdf_text = extract_pdf_text(pdf_path)
    new_data = parse_tabular_data(pdf_text)
    new_df = pd.DataFrame(new_data)
    
    customer_name, document_date, bsa_product, ach, rdc = extract_dynamic_details(filename, pdf_text)
    new_df['Customer Name'] = customer_name
    new_df['Document Date'] = document_date
    new_df['BSA Product'] = bsa_product
    new_df['ACH'] = ach
    new_df['RDC'] = rdc
    
    master_df = pd.concat([master_df, new_df], ignore_index=True)

print(master_df.head())
master_df.to_csv("final_output.csv", index=False)

### try to convert to image###
import pdfplumber
import pytesseract
from pdf2image import convert_from_path
import pandas as pd
import os

# Configure Pytesseract path to where the Tesseract executable is located
pytesseract.pytesseract.tesseract_cmd = r'path_to_tesseract.exe'  # Update this path

def extract_pdf_text(pdf_file):
    text = ""
    # Try extracting text using pdfplumber
    try:
        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                text += page.extract_text() or ''
    except Exception as e:
        print(f"Failed to extract using pdfplumber due to: {e}")
    # If no text was found, use OCR
    if not text:
        print("No text found with pdfplumber, attempting OCR...")
        images = convert_from_path(pdf_file)
        for image in images:
            text += pytesseract.image_to_string(image)
    return text

def parse_tabular_data(text):
    lines = text.split('\n')
    data = []
    start = False
    for line in lines:
        if "Tax ID Legal/Primary Name TMS BSA KYC" in line:
            start = True
            continue
        if start and line.strip() == "":
            break
        if start:
            parts = line.split()
            if len(parts) >= 6:
                data.append({
                    "Tax_ID_new": parts[0],
                    "Legal/Primary Name": " ".join(parts[1:-2]),
                    "TMS": parts[-2],
                    "BSA-KYC": parts[-1]
                })
    return data

# List all PDF files in the current directory
pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]
data = []

for file_name in pdf_files:
    text = extract_pdf_text(file_name)
    new_data = parse_tabular_data(text)
    data.extend(new_data)

# Convert the list to a DataFrame
df = pd.DataFrame(data)
print(df.head())
df.to_csv("final_output.csv", index=False)

### easy ocr############
import easyocr
import pdf2image
import os

def convert_pdf_to_images(pdf_path):
    """Converts each page of a PDF to an image."""
    return pdf2image.convert_from_path(pdf_path, dpi=300, fmt='jpeg')

def extract_text_from_images(images):
    """Uses EasyOCR to extract text from a list of image files."""
    reader = easyocr.Reader(['en'])  # Assuming English; add other languages if needed
    text = []
    for image in images:
        results = reader.readtext(image, paragraph=True)  # Use paragraph mode to better format the output
        page_text = " ".join([result[1] for result in results])
        text.append(page_text)
    return text

def process_pdf(pdf_path):
    """Converts a PDF to images, extracts text, and prints the results."""
    images = convert_pdf_to_images(pdf_path)
    extracted_text = extract_text_from_images(images)
    for page_number, page_text in enumerate(extracted_text, start=1):
        print(f"Text from Page {page_number}: {page_text}\n")

# Example usage
pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]
for pdf_file in pdf_files:
    print(f"Processing {pdf_file}...")
    process_pdf(pdf_file)

### without poppler###
import fitz  # PyMuPDF
import os

def convert_pdf_to_images(pdf_path):
    """Converts each page of a PDF to an image using PyMuPDF."""
    doc = fitz.open(pdf_path)
    images = []
    for page in doc:
        pix = page.get_pixmap()
        img_path = f"page_{page.number}.png"
        pix.save(img_path)
        images.append(img_path)
    return images

def extract_text_from_images(images):
    import easyocr
    reader = easyocr.Reader(['en'])  # Assuming English; add other languages if needed
    text = []
    for image_path in images:
        results = reader.readtext(image_path, paragraph=True)
        page_text = " ".join([result[1] for result in results])
        text.append(page_text)
    return text

def process_pdf(pdf_path):
    """Converts a PDF to images and extracts text."""
    images = convert_pdf_to_images(pdf_path)
    extracted_text = extract_text_from_images(images)
    for page_number, page_text in enumerate(extracted_text, start=1):
        print(f"Text from Page {page_number}: {page_text}")

# Example usage
pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]
for pdf_file in pdf_files:
    print(f"Processing {pdf_file}...")
    process_pdf(pdf_file)

###regex pattern
pattern = r"(?P<ID>\d{2}-\d{8})\s+(?P<Name>[\w\s]+(?:INC|LLC|INS))\s+(?P<PMS>Yes)\s+(?P<ASA_KPC>N/A, online only)"

###try###
import fitz  # PyMuPDF
import os
import pandas as pd
import easyocr
import re

def convert_pdf_to_images(pdf_path):
    """Converts each page of a PDF to an image using PyMuPDF."""
    doc = fitz.open(pdf_path)
    images = []
    for page in doc:
        pix = page.get_pixmap()
        img_path = f"page_{page.number}.png"
        pix.save(img_path)
        images.append(img_path)
    return images

def extract_text_from_images(images):
    reader = easyocr.Reader(['en'])  # Assuming English; add other languages if needed
    text = []
    for image_path in images:
        results = reader.readtext(image_path, paragraph=True)
        page_text = " ".join([result[1] for result in results])
        text.append(page_text)
    return text

def extract_data(text):
    """ Extracts and parses data after the specific header. """
    header = "Tax ID Legal/Primary Name TMS BSA KYC"
    start_index = text.find(header) + len(header) if header in text else -1
    if start_index == -1:
        return []  # Header not found, or no data following the header
    
    data_text = text[start_index:]
    # Regex to match the expected format of records
    pattern = r"(\d{2}-\d{7,8})\s+([\w\s]+?)\s+(Yes|No)\s+(.*?)(?=\s+\d{2}-\d{7,8}\s+|$)"
    matches = re.finditer(pattern, data_text, re.IGNORECASE)
    
    records = []
    for match in matches:
        records.append({
            'Tax ID': match.group(1),
            'Legal/Primary Name': match.group(2).strip(),
            'TMS': match.group(3),
            'BSA KYC': match.group(4).strip()
        })
    
    return records

def process_pdf(pdf_path):
    """Process a single PDF file."""
    images = convert_pdf_to_images(pdf_path)
    text = " ".join(extract_text_from_images(images))
    return extract_data(text)

# Example usage
df = pd.DataFrame()
pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]
for pdf_file in pdf_files:
    print(f"Processing {pdf_file}...")
    records = process_pdf(pdf_file)
    if records:
        df = pd.concat([df, pd.DataFrame(records)], ignore_index=True)

print(df)

